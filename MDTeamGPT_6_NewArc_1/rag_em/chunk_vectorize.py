import re
from pathlib import Path
from typing import List,Optional
from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings
from langchain.schema import Document
from collections import defaultdict

class MedicalVectorProcessor:
    def __init__(self, use_openai=False):
        self.embeddings = OpenAIEmbeddings() if use_openai else HuggingFaceEmbeddings(model_name="BAAI/bge-small-en-v1.5")
        self._init_splitters()
        self.specialty_keywords = {
            "Trauma Surgery": ["fracture", "hemorrhage", "gunshot", "amputation", "exploratory laparotomy", "damage control"],
            "Pediatrics": ["child", "neonatal", "vaccine", "growth chart", "ADHD", "pediatrician", "well-baby"],
            "Toxicology": ["overdose", "poison", "antidote", "venom", "heavy metals", "naloxone", "toxidrome"],
            "Neurology": ["stroke", "seizure", "Alzheimer's", "migraine", "EEG", "multiple sclerosis", "neuropathy"],
            "Pulmonology": ["COPD", "asthma", "ventilator", "pneumonia", "bronchoscopy", "pulmonary fibrosis", "ABG"],
            "Gastroenterology": ["endoscopy", "colonoscopy", "IBS", "GERD", "cirrhosis", "Crohn's", "hepatitis"],
            "Infectious Disease": ["antibiotics", "sepsis", "HIV", "tuberculosis", "COVID-19", "antimicrobial", "viral load"],
            "Orthopedics": ["fracture", "ACL", "arthroplasty", "spinal fusion", "carpal tunnel", "dislocation", "cast"],
            "Obstetrics": ["prenatal", "C-section", "placenta", "eclampsia", "ultrasound", "postpartum", "OB/GYN"],
            "Psychiatry": ["depression", "bipolar", "schizophrenia", "SSRI", "psychosis", "anxiety", "therapy"],
            "Radiology": ["X-ray", "MRI", "CT scan", "ultrasound", "fluoroscopy", "mammogram", "contrast"],
            "Anesthesiology": ["intubation", "propofol", "epidural", "general anesthesia", "sedation", "pain management"],
            "Nephrology": ["dialysis", "AKI", "CKD", "kidney stone", "glomerulonephritis", "creatinine", "ESRD"],
            "Hematology": ["anemia", "leukemia", "hemoglobin", "coagulation", "blood transfusion", "lymphoma", "DVT"],
            "Endocrinology": ["diabetes", "insulin", "thyroid", "hormone", "osteoporosis", "metabolic", "HbA1c"],
            "Rheumatology": ["arthritis", "lupus", "gout", "autoimmune", "biologics", "SjÃ¶gren's", "inflammation"],
            "Dermatology": ["acne", "biopsy", "melanoma", "eczema", "psoriasis", "rash", "Mohs surgery"],
            "General Medicine": ["primary care", "PCP", "referral", "annual physical", "hypertension", "preventive care"],
            "Urology": ["kidney stone", "BPH", "cystoscopy", "prostate", "UTI", "incontinence", "vasectomy"],
            "Cardiology": ["ECG", "echocardiogram", "heart failure", "arrhythmia", "stent", "myocardial", "hypertension"],
            "Emergency": ["trauma", "resuscitation", "ER", "critical care", "CPR", "triage", "life-threatening"],
        }

        # 2. æ€¥è¯Šå­ä¸“ä¸šæ˜ å°„ï¼ˆæ–°ï¼‰
        self.emergency_subspecialties = {
        
            # åˆ›ä¼¤æ€¥ç—‡
            "Trauma Surgery": [
                "gunshot wound", "stab wound", "polytrauma", "hemorrhagic shock",
                "flail chest", "tension pneumothorax", "FAST exam", "abdominal trauma",
                "traumatic brain injury", "amputation", "crush injury"
            ],
             # å„¿ç§‘æ€¥ç—‡
            "Pediatrics": [
                "neonatal resuscitation", "pediatric code", "child abuse", "SIDS",
                "bronchiolitis", "croup", "epiglottitis", "pediatric trauma",
                "febrile seizure", "intussusception", "Reye syndrome"
            ],
             # å¿ƒè„æ€¥ç—‡
            "Cardiology": [
                "STEMI", "NSTEMI", "chest pain", "cardiac arrest", "ACS", 
                "ventricular fibrillation", "unstable angina", "aortic dissection",
                "tamponade", "cardiogenic shock", "complete heart block"
            ],
            # ä¸­æ¯’æ€¥ç—‡
            "Toxicology": [
                "overdose", "opioid toxicity", "TCA overdose", "carbon monoxide",
                "organophosphate", "caustic ingestion", "anticholinergic crisis",
                "serotonin syndrome", "lithium toxicity", "methanol poisoning"
            ],
            # ç¥ç»æ€¥ç—‡
            "Neurology": [
                "CVA", "hemorrhagic stroke", "ischemic stroke", "status epilepticus",
                "meningitis", "encephalitis", "GCS <8", "brain herniation",
                "spinal cord compression", "myasthenic crisis", "Guillain-BarrÃ©"
            ],
            # å‘¼å¸æ€¥ç—‡
            "Pulmonology": [
                "respiratory arrest", "ARDS", "pulmonary embolism", "tension pneumothorax",
                "severe asthma", "COPD exacerbation", "massive hemoptysis", 
                "difficult airway", "foreign body aspiration", "pulmonary edema"
            ],
            # æ¶ˆåŒ–æ€¥ç—‡
            "Gastroenterology": [
                "GI bleed", "esophageal varices", "perforated ulcer", "bowel obstruction",
                "acute pancreatitis", "toxic megacolon", "liver failure", 
                "Mallory-Weiss tear", "volvulus", "mesenteric ischemia"
            ],
            # æ„ŸæŸ“æ€¥ç—‡
            "Infectious Disease": [
                "septic shock", "meningococcemia", "necrotizing fasciitis",
                "toxic shock syndrome", "rabies exposure", "malaria complications",
                "dengue shock", "Ebola", "anthrax", "plague"
            ],
            # éª¨ç§‘æ€¥ç—‡
            "Orthopedics": [
                "open fracture", "compartment syndrome", "cauda equina",
                "septic arthritis", "dislocation", "spinal fracture",
                "pelvic fracture", "pathologic fracture", "osteomyelitis"
            ],
            # å¦‡äº§æ€¥ç—‡
            "Obstetrics": [
                "eclampsia", "postpartum hemorrhage", "placental abruption",
                "uterine rupture", "amniotic fluid embolism", "shoulder dystocia",
                "ruptured ectopic", "HELLP syndrome", "uterine inversion"
            ],
            # ç²¾ç¥æ€¥ç—‡
            "Psychiatry": [
                "suicidal ideation", "violent behavior", "catatonia",
                "neuroleptic malignant", "akathisia", "serotonin syndrome",
                "alcohol withdrawal", "delirium tremens", "excited delirium"
            ],
            # å½±åƒæ€¥ç—‡
            "Radiology": [
                "contrast reaction", "aortic rupture", "pneumothorax",
                "bowel perforation", "cerebral hemorrhage", "foreign body",
                "dissection", "ischemic bowel", "abscess"
            ],
            # éº»é†‰æ€¥ç—‡
            "Anesthesiology": [
                "difficult airway", "failed intubation", "malignant hyperthermia",
                "local anesthetic toxicity", "anaphylaxis", "opioid overdose",
                "bronchospasm", "aspiration", "total spinal"
            ],
            # è‚¾è„æ€¥ç—‡
            "Nephrology": [
                "hyperkalemia", "uremic encephalopathy", "dialysis emergency",
                "acute kidney injury", "renal colic", "bladder rupture",
                "nephrotic crisis", "contrast nephropathy"
            ],
            # è¡€æ¶²æ€¥ç—‡
            "Hematology": [
                "DIC", "massive transfusion", "thrombotic thrombocytopenic purpura",
                "hemolytic crisis", "neutropenic fever", "coagulopathy",
                "hemophilia bleed", "sickle cell crisis"
            ],
            # å†…åˆ†æ³Œæ€¥ç—‡
            "Endocrinology": [
                "DKA", "HHS", "thyroid storm", "myxedema coma",
                "adrenal crisis", "hypoglycemia", "pheochromocytoma crisis",
                "hypercalcemic crisis"
            ],
            # é£æ¹¿æ€¥ç—‡
            "Rheumatology": [
                "vasculitic emergency", "scleroderma renal crisis",
                "acute gout", "SLE flare", "myositis", "ankylosing spondylitis fracture"
            ],
            # çš®è‚¤æ€¥ç—‡
            "Dermatology": [
                "SJS", "TEN", "necrotizing fasciitis", "angioedema",
                "erythroderma", "purpura fulminans", "toxic epidermal necrolysis"
            ],
            # æ³Œå°¿æ€¥ç—‡
            "Urology": [
                "testicular torsion", "priapism", "renal colic", "urinary retention",
                "Fournier gangrene", "bladder rupture", "uretral trauma"
            ]
        }

    def _init_splitters(self):
        """åˆå§‹åŒ–åˆ†å—å™¨"""
        self.header_splitter = MarkdownHeaderTextSplitter(
            headers_to_split_on=[("#", "Chapter"), ("##", "Section")]
        )
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=100,
            separators=["\n\n", "\n", ".", "ã€‚", "!", "?", "..."],
            keep_separator=True  # ä¿ç•™åˆ†éš”ç¬¦é¿å…è¯­ä¹‰æ–­è£‚
        )

    def process_file(self, file_path: str) -> List[Document]:
        text = Path(file_path).read_text(encoding='utf-8')
        chunks = self.header_splitter.split_text(text)  # å…ˆåˆ†å—
        
        final_chunks = []
        for chunk in chunks:
            # å¯¹æ¯ä¸ªåˆ†å—å•ç‹¬æ£€æµ‹ä¸“ä¸š
            chunk_specialty = self._detect_specialty(chunk.page_content)
            
            # å¤„ç†è¿‡å¤§åˆ†å—
            if len(chunk.page_content) > 800:
                sub_chunks = self.text_splitter.split_documents([chunk])
                for sub_chunk in sub_chunks:
                    sub_chunk.metadata.update({
                        "source": Path(file_path).stem,
                        "specialty": chunk_specialty  # å­å—ç»§æ‰¿çˆ¶å—ä¸“ä¸š
                    })
                final_chunks.extend(sub_chunks)
            else:
                chunk.metadata.update({
                    "source": Path(file_path).stem,
                    "specialty": chunk_specialty  # ç›´æ¥èµ‹å€¼
                })
                final_chunks.append(chunk)
        return final_chunks

    def _detect_specialty(self, text: str) -> str:
        """Enhanced specialty detection with emergency mapping"""
        #self.debug_classification(text)

        text_lower = text.lower()
        keyword_counts = defaultdict(int)
    
        # ç»Ÿè®¡æ‰€æœ‰åŒ¹é…çš„å…³é”®è¯é¢‘æ¬¡
        for spec, keywords in self.specialty_keywords.items():
            for kw in keywords:
                if kw in text_lower:
                    keyword_counts[spec] += 1

        # print("\n=== DEBUG: Keyword Counts ===")  # Debug info
        # for spec, count in keyword_counts.items():
        #     print(f"{spec}: {count} hits")

        if not keyword_counts:
            print("DEBUG: No keywords matched, returning 'General'")
            return "General Medicine"

        # è¿”å›é¢‘æ¬¡æœ€é«˜çš„ä¸“ä¸šï¼ˆåŒé¢‘æ¬¡æ—¶æŒ‰é¢„è®¾ä¼˜å…ˆçº§ï¼‰
        max_count = max(keyword_counts.values())
        candidates = [k for k,v in keyword_counts.items() if v == max_count]

        #print(f"\nDEBUG: Max count={max_count}, Candidates={candidates}")  # Debug info

        # # ä¼˜å…ˆçº§ï¼šæ€¥è¯Šå­ä¸“ä¸š > å¸¸è§„ä¸“ä¸š > é€šç”¨æ€¥è¯Š
        # for spec in candidates:
        #     if spec in self.emergency_subspecialties:
        #         return spec
        # if "Emergency" in candidates:
        #     print("DEBUG: Selected 'Emergency' (fallback)")
        #     return "Emergency"
        
        # print(f"DEBUG: Default selection, first candidate: '{candidates[0]}'")
        return candidates[0]  # é»˜è®¤è¿”å›ç¬¬ä¸€ä¸ª
    
    def debug_classification(self, text):
        text_lower = text.lower()
        print("\n=== Debug Start ===")
        
        # æ£€æŸ¥æ€¥è¯Šå­ä¸“ä¸š
        print("Emergency Subspecialty Check:")
        for spec, terms in self.emergency_subspecialties.items():
            matches = [t for t in terms if t.lower() in text_lower]
            if matches:
                print(f"â†’ {spec}: {matches}")
        
        # æ£€æŸ¥å¸¸è§„ä¸“ä¸š
        print("\nRegular Specialty Check:")
        for spec, terms in self.specialty_keywords.items():
            if spec == "Emergency": continue
            matches = [t for t in terms if t.lower() in text_lower]
            if matches:
                print(f"â†’ {spec}: {matches}")
        
        print("=== Debug End ===\n")

     

    def build_index(self, dir_path: str, output_path: str) -> FAISS:
        """æ„å»ºå‘é‡ç´¢å¼•"""
        """ä»ç›®å½•æ„å»ºç´¢å¼•ï¼Œè‡ªåŠ¨å¤„ç†æ‰€æœ‰.mdæ–‡ä»¶"""
        dir_path = Path(dir_path)
        if not dir_path.exists():
            raise ValueError(f"Directory not found: {dir_path}")
        
        md_files = list(dir_path.glob("*.md"))
        if not md_files:
            raise ValueError(f"No .md files found in {dir_path}")
        
        print(f"Found {len(md_files)} Markdown files:")
        for md_file in md_files:
            print(f"- {md_file.name}")
            
        all_chunks = []
        for md_file in md_files:
            print(f"Processing {md_file}...")
            all_chunks.extend(self.process_file(str(md_file)))

        print(f"Total chunks: {len(all_chunks)}")
        vector_db = FAISS.from_documents(all_chunks, self.embeddings)
        if output_path:
            vector_db.save_local(output_path)
            print(f"âœ… Index saved to {output_path}")
        return vector_db
    

    def update_index(self, new_dir: str, existing_index_path: str) -> FAISS:
        """
        å¢é‡æ›´æ–°ç°æœ‰å‘é‡æ•°æ®åº“
        :param new_markdown_dir: æ–°å¢Markdownæ–‡ä»¶ç›®å½•
        :param existing_index_path: å·²å­˜åœ¨çš„FAISSç´¢å¼•è·¯å¾„
        """
        # 1. åŠ è½½ç°æœ‰ç´¢å¼•
        try:
            db = FAISS.load_local(existing_index_path, self.embeddings)
            print(f"âœ… Load existing index from {existing_index_path} successfully !")
        except Exception as e:
            print(f"âš ï¸ Failed to load index ({str(e)}), creating new index.")
            db = FAISS.from_documents([], self.embeddings)  # ç©ºç´¢å¼•

        # 2. å¤„ç†æ–°å¢æ–‡ä»¶
        new_files = list(Path(new_dir).glob("*.md"))
        if not new_files:
            print(f"â­ï¸ No .md files found in {new_dir}")
            return db

        # 3. å»é‡æ£€æŸ¥ï¼ˆé¿å…é‡å¤æ·»åŠ ï¼‰
        existing_sources = set(doc.metadata.get("source") for doc in db.docstore._dict.values())
        new_chunks = []
        
        for md_file in new_files:
            if md_file.stem not in existing_sources:
                new_chunks.extend(self.process_file(str(md_file)))
                print(f"Added {md_file}")
            else:
                print(f"â­ï¸ Jump exist files: {md_file.name}")

        # 4. å¢é‡æ·»åŠ 
        if new_chunks:
            db.add_documents(new_chunks)
            print(f"ğŸ†• New add {len(new_chunks)} chunks from {len(new_files)} files ")
        else:
            print("ğŸ”„ No new cotent for update!")

        # 5. ä¿å­˜æ›´æ–°åçš„ç´¢å¼•ï¼ˆè¦†ç›–åŸè·¯å¾„ï¼‰
        db.save_local(existing_index_path)
        print(f"ğŸ’¾ Index has update and store at {existing_index_path}")
        return db

# æµ‹è¯•å¢é‡æ›´æ–°
def test_incremental_update():
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_dir = "test_data"
    Path(test_dir).mkdir(exist_ok=True)
    Path(f"{test_dir}/old").mkdir(exist_ok=True)
    Path(f"{test_dir}/new").mkdir(exist_ok=True)

    Path(f"{test_dir}/old/file1.md").write_text("# æ—§æ–‡ä»¶\nå†…å®¹1")
    Path(f"{test_dir}/new/file2.md").write_text("# æ–°æ–‡ä»¶\nå†…å®¹2")
    
    # é¦–æ¬¡æ„å»º
    processor = MedicalVectorProcessor()
    processor.build_index(f"{test_dir}/old", "test_index")
    
    # å¢é‡æ›´æ–°
    processor.update_index(f"{test_dir}/new", "test_index")
    
    # éªŒè¯ç»“æœ
    db = FAISS.load_local("test_index", processor.embeddings)
    sources = {doc.metadata["source"] for doc in db.docstore._dict.values()}
    assert "file1" in sources and "file2" in sources
    print("âœ… æµ‹è¯•é€šè¿‡")

if __name__ == "__main__":
   # test_incremental_update()
   # åˆå§‹åŒ–å¤„ç†å™¨
    processor = MedicalVectorProcessor(use_openai=False)  # ä½¿ç”¨å…è´¹æ¨¡å‹
    
    # é¦–æ¬¡è¿è¡Œï¼šå¤„ç†åŒ…å«9ä¸ªMarkdownçš„æ–‡ä»¶å¤¹
    print("=== Building initial index ===")
    db = processor.build_index(
        dir_path="data/EM_textbook/processed_markdown",  # å­˜æ”¾9ä¸ªåˆå§‹æ–‡ä»¶çš„æ–‡ä»¶å¤¹
        output_path="data/EM_textbook/FAISS_index"
    )
    
    # # ç¤ºä¾‹ï¼šåç»­æ›´æ–°ï¼ˆå¯ä»¥æ³¨é‡Šæ‰åˆå§‹è¿è¡Œï¼‰
    # print("\n=== Updating index ===")
    # processor.update_index(
    #     new_dir="data/EM_textbook/processed_markdown",
    #     existing_index_path="data/EM_textbook/FAISS_index"
    # )
  